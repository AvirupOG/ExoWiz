{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we6_sPYiiYbu"
      },
      "outputs": [],
      "source": [
        "!pip -q install lightkurve==2.* numpy pandas scipy astropy tqdm pyarrow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detrending + BLS pipeline**"
      ],
      "metadata": {
        "id": "RMb1pvAPmlEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Dict, Any, List, Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from astropy.timeseries import BoxLeastSquares\n",
        "from scipy.signal import savgol_filter\n",
        "import lightkurve as lk\n",
        "\n",
        "def _to_clean_arrays(time_in, flux_in):\n",
        "    t = np.array(time_in, dtype=float)\n",
        "    f = np.array(flux_in, dtype=float)\n",
        "    m = np.isfinite(t) & np.isfinite(f)\n",
        "    t, f = t[m], f[m]\n",
        "    if len(t) == 0:\n",
        "        return t, f\n",
        "    order = np.argsort(t)\n",
        "    return t[order], f[order]\n",
        "\n",
        "def _estimate_baseline_days(time):\n",
        "    if len(time) < 2:\n",
        "        return 0.0\n",
        "    return float(np.nanmax(time) - np.nanmin(time))\n",
        "\n",
        "def _savgol_detrend(time, flux, window_length=401, polyorder=2):\n",
        "    if len(flux) < 7:\n",
        "        return time, flux\n",
        "    wl = max(5, int(window_length))\n",
        "    wl = wl if wl % 2 == 1 else wl + 1\n",
        "    wl = min(wl, len(flux) - (1 - len(flux) % 2))\n",
        "    if wl < 5:\n",
        "        return time, flux\n",
        "    trend = savgol_filter(flux, window_length=wl, polyorder=polyorder, mode=\"interp\")\n",
        "    med = np.nanmedian(trend) if np.isfinite(trend).any() else 1.0\n",
        "    trend = np.where(trend == 0, med, trend)\n",
        "    detrended = flux / trend - 1.0\n",
        "    return time, detrended\n",
        "\n",
        "def _lk_flatten(time, flux, window_length=401, polyorder=2, break_tolerance=5):\n",
        "    try:\n",
        "        lc = lk.LightCurve(time=time, flux=flux)\n",
        "        wl = max(5, int(window_length))\n",
        "        wl = wl if wl % 2 == 1 else wl + 1\n",
        "        lc_flat = lc.flatten(window_length=wl, polyorder=polyorder, break_tolerance=break_tolerance)\n",
        "        return np.array(lc_flat.time.value), np.array(lc_flat.flux.value)\n",
        "    except Exception:\n",
        "        return _savgol_detrend(time, flux, window_length=window_length, polyorder=polyorder)\n",
        "\n",
        "def detrend_series(time_in, flux_in,\n",
        "                   method: str = \"lightkurve\",\n",
        "                   window_length: Optional[int] = None,\n",
        "                   polyorder: int = 2,\n",
        "                   cadence_min: Optional[float] = None,\n",
        "                   max_transit_hours: float = 10.0) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    t, f = _to_clean_arrays(time_in, flux_in)\n",
        "    if len(t) < 50:\n",
        "        return t, f\n",
        "\n",
        "    if window_length is None:\n",
        "        if cadence_min is None:\n",
        "            dt_days = np.nanmedian(np.diff(t)) if len(t) > 1 else 0.0208333\n",
        "            cadence_min = float(dt_days * 24.0 * 60.0)\n",
        "        target_minutes = max_transit_hours * 60.0 * 2.5\n",
        "        window_length = max(51, int(round(target_minutes / max(cadence_min, 1e-6))))\n",
        "        if window_length % 2 == 0:\n",
        "            window_length += 1\n",
        "\n",
        "    if method == \"lightkurve\":\n",
        "        return _lk_flatten(t, f, window_length=window_length, polyorder=polyorder)\n",
        "    else:\n",
        "        return _savgol_detrend(t, f, window_length=window_length, polyorder=polyorder)\n",
        "\n",
        "def _period_limits_from_baseline(baseline_days: float,\n",
        "                                 min_period: float = 0.3,\n",
        "                                 max_period: Optional[float] = None) -> Tuple[float, float]:\n",
        "    if max_period is None:\n",
        "        max_period = max(1.0, 0.9 * max(baseline_days, 1.0))\n",
        "        max_period = min(max_period, 100.0)  # safety cap\n",
        "    return max(min_period, 0.05), max_period\n",
        "\n",
        "def run_bls(time: np.ndarray,\n",
        "            flux: np.ndarray,\n",
        "            min_period: float = 0.3,\n",
        "            max_period: Optional[float] = None,\n",
        "            min_dur_hours: float = 0.5,\n",
        "            max_dur_hours: float = 10.0,\n",
        "            n_durations: int = 25,\n",
        "            oversample: int = 10,\n",
        "            minimum_n_transit: int = 3) -> Dict[str, Any]:\n",
        "    if len(time) < 100:\n",
        "        return {}\n",
        "\n",
        "    baseline = _estimate_baseline_days(time)\n",
        "    pmin, pmax = _period_limits_from_baseline(baseline, min_period=min_period, max_period=max_period)\n",
        "\n",
        "    dur_grid_days = np.linspace(min_dur_hours/24.0, max_dur_hours/24.0, n_durations)\n",
        "\n",
        "    bls = BoxLeastSquares(time, flux)\n",
        "    res = bls.autopower(dur_grid_days,\n",
        "                        minimum_n_transit=minimum_n_transit,\n",
        "                        frequency_factor=oversample)\n",
        "\n",
        "    sel = (res.period >= pmin) & (res.period <= pmax) & np.isfinite(res.power)\n",
        "    if not np.any(sel):\n",
        "        return {}\n",
        "\n",
        "    out = {\n",
        "        \"period\": np.array(res.period[sel]),\n",
        "        \"power\": np.array(res.power[sel]),\n",
        "        \"duration\": np.array(res.duration[sel]),\n",
        "        \"transit_time\": np.array(res.transit_time[sel]),\n",
        "        \"depth\": np.array(res.depth[sel]) if hasattr(res, \"depth\") else None,\n",
        "        \"depth_err\": np.array(res.depth_err[sel]) if hasattr(res, \"depth_err\") else None,\n",
        "        \"snr\": None,\n",
        "    }\n",
        "    if out[\"depth\"] is not None and out[\"depth_err\"] is not None:\n",
        "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
        "            out[\"snr\"] = out[\"depth\"] / np.where(out[\"depth_err\"] == 0, np.nan, out[\"depth_err\"])\n",
        "\n",
        "    return out\n",
        "\n",
        "def _find_top_peaks(period, power, k_top=3, min_separation=0.02):\n",
        "    if len(period) < 5:\n",
        "        return np.argsort(power)[::-1][:k_top]\n",
        "\n",
        "    is_peak = (power[1:-1] > power[:-2]) & (power[1:-1] > power[2:])\n",
        "    peak_idx = np.where(is_peak)[0] + 1\n",
        "    if len(peak_idx) == 0:\n",
        "        peak_idx = np.array([np.argmax(power)])\n",
        "\n",
        "    candidates = peak_idx[np.argsort(power[peak_idx])[::-1]]\n",
        "\n",
        "    selected = []\n",
        "    for i in candidates:\n",
        "        if len(selected) >= k_top:\n",
        "            break\n",
        "        if all(np.abs(period[i] - period[j]) > min_separation * period[i] for j in selected):\n",
        "            selected.append(i)\n",
        "\n",
        "    if len(selected) < k_top:\n",
        "        filler = np.argsort(power)[::-1]\n",
        "        for i in filler:\n",
        "            if i in selected:\n",
        "                continue\n",
        "            if all(np.abs(period[i] - period[j]) > min_separation * period[i] for j in selected):\n",
        "                selected.append(i)\n",
        "            if len(selected) >= k_top:\n",
        "                break\n",
        "\n",
        "    return np.array(selected[:k_top], dtype=int)\n",
        "\n",
        "def process_block_row(row: pd.Series,\n",
        "                      detrend_method: str = \"lightkurve\",\n",
        "                      max_transit_hours: float = 10.0,\n",
        "                      bls_top_k: int = 3,\n",
        "                      save_power_every_n: int = 10,\n",
        "                      decimate_power: int = 5) -> List[Dict[str, Any]]:\n",
        "    time = row.get(\"time\")\n",
        "    flux = row.get(\"flux\")\n",
        "    if time is None or flux is None:\n",
        "        return []\n",
        "\n",
        "    t, f = _to_clean_arrays(time, flux)\n",
        "    if len(t) < 100:\n",
        "        return []\n",
        "\n",
        "    t_d, f_d = detrend_series(\n",
        "        t, f,\n",
        "        method=detrend_method,\n",
        "        cadence_min=row.get(\"cadence_min\"),\n",
        "        max_transit_hours=max_transit_hours\n",
        "    )\n",
        "\n",
        "    f_d = f_d - np.nanmedian(f_d)\n",
        "\n",
        "    bls_out = run_bls(\n",
        "        t_d, f_d,\n",
        "        min_period=0.3,\n",
        "        max_period=None,\n",
        "        min_dur_hours=0.5,\n",
        "        max_dur_hours=max_transit_hours,\n",
        "        n_durations=25,\n",
        "        oversample=10,\n",
        "        minimum_n_transit=3\n",
        "    )\n",
        "    if not bls_out:\n",
        "        return []\n",
        "\n",
        "    period = bls_out[\"period\"]\n",
        "    power = bls_out[\"power\"]\n",
        "    duration = bls_out[\"duration\"]\n",
        "    t0 = bls_out[\"transit_time\"]\n",
        "    depth = bls_out[\"depth\"]\n",
        "    depth_err = bls_out[\"depth_err\"]\n",
        "    snr_arr = bls_out[\"snr\"]\n",
        "\n",
        "    peaks = _find_top_peaks(period, power, k_top=bls_top_k, min_separation=0.02)\n",
        "\n",
        "    attach_power = False\n",
        "    if save_power_every_n and save_power_every_n > 0:\n",
        "\n",
        "        attach_power = (int(row.name) % save_power_every_n == 0)\n",
        "\n",
        "    candidates = []\n",
        "    for rank, i in enumerate(peaks, start=1):\n",
        "        cand = {\n",
        "            \"obs_block_id\": row.get(\"obs_block_id\"),\n",
        "            \"target_id\": row.get(\"target_id\"),\n",
        "            \"label\": row.get(\"label\"),\n",
        "            \"mission\": row.get(\"mission\"),\n",
        "            \"sector\": row.get(\"sector\"),\n",
        "            \"quarter\": row.get(\"quarter\"),\n",
        "            \"campaign\": row.get(\"campaign\"),\n",
        "            \"rank\": rank,\n",
        "            \"period\": float(period[i]),\n",
        "            \"epoch\": float(t0[i]),\n",
        "            \"duration\": float(duration[i]),\n",
        "            \"depth\": float(depth[i]) if depth is not None else np.nan,\n",
        "            \"depth_err\": float(depth_err[i]) if depth_err is not None else np.nan,\n",
        "            \"snr\": float(snr_arr[i]) if snr_arr is not None and np.isfinite(snr_arr[i]) else np.nan,\n",
        "            \"power\": float(power[i]),\n",
        "            \"n_points\": int(len(t_d)),\n",
        "            \"baseline_days\": float(_estimate_baseline_days(t_d)),\n",
        "            \"detrend_method\": detrend_method,\n",
        "        }\n",
        "        if attach_power:\n",
        "            step = max(1, int(decimate_power))\n",
        "            cand[\"bls_period_grid\"] = period[::step].tolist()\n",
        "            cand[\"bls_power_grid\"] = power[::step].tolist()\n",
        "        candidates.append(cand)\n",
        "\n",
        "    return candidates\n",
        "\n",
        "\n",
        "def run_bls_pipeline(vet_df: pd.DataFrame,\n",
        "                     detrend_method: str = \"lightkurve\",\n",
        "                     max_transit_hours: float = 10.0,\n",
        "                     bls_top_k: int = 3,\n",
        "                     save_power_every_n: int = 10,\n",
        "                     decimate_power: int = 5) -> pd.DataFrame:\n",
        "    all_cands: List[Dict[str, Any]] = []\n",
        "    for idx, row in tqdm(vet_df.iterrows(), total=len(vet_df), desc=\"Detrend+BLS\"):\n",
        "        try:\n",
        "            cands = process_block_row(\n",
        "                row,\n",
        "                detrend_method=detrend_method,\n",
        "                max_transit_hours=max_transit_hours,\n",
        "                bls_top_k=bls_top_k,\n",
        "                save_power_every_n=save_power_every_n,\n",
        "                decimate_power=decimate_power\n",
        "            )\n",
        "            all_cands.extend(cands)\n",
        "        except Exception as e:\n",
        "            obid = row.get(\"obs_block_id\", \"?\")\n",
        "            print(f\"[WARN] failed on row {idx} ({obid}): {repr(e)}\")\n",
        "\n",
        "    if not all_cands:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    cand_df = pd.DataFrame.from_records(all_cands)\n",
        "    cand_df = cand_df.sort_values(\n",
        "        by=[\"target_id\", \"rank\", \"power\"],\n",
        "        ascending=[True, True, False]\n",
        "    ).reset_index(drop=True)\n",
        "    return cand_df\n"
      ],
      "metadata": {
        "id": "9w1v-Kehnzry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "INPUT_PARQUET = \"/content/vetting_kepler.parquet\"\n",
        "OUTPUT_PARQUET = \"/content/drive/candidates_bls.parquet\"\n",
        "\n",
        "vet_df = pd.read_parquet(INPUT_PARQUET)\n",
        "print(\"Loaded\", len(vet_df), \"observing blocks\")\n",
        "display(vet_df.head(2))\n"
      ],
      "metadata": {
        "id": "UDB3R53EoojB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cand_df = run_bls_pipeline(\n",
        "    vet_df,\n",
        "    detrend_method=\"lightkurve\",\n",
        "    max_transit_hours=10.0,\n",
        "    bls_top_k=3,\n",
        "    save_power_every_n=10,\n",
        "    decimate_power=10\n",
        ")\n",
        "\n",
        "print(\"Found\", len(cand_df), \"BLS candidates\")\n",
        "display(cand_df.head())"
      ],
      "metadata": {
        "id": "vx-iLZ70ovJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "tmp_out = \"candidates_bls.parquet\"\n",
        "cand_df.to_parquet(tmp_out, index=False)\n",
        "files.download(tmp_out)"
      ],
      "metadata": {
        "id": "wXZWyJGKo8BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EoQbkes1pBVg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}