# -*- coding: utf-8 -*-
"""KOI_Table_Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HsDKCuh0SeuGPWiBjJJH3AVEW4jSPa-N
"""

#@title ðŸš€ Setup (installs + folders)
!pip -q install pandas scikit-learn joblib requests matplotlib lightkurve astroquery astropy scipy plotly reportlab shap torch cloudflared streamlit

import os, matplotlib
matplotlib.use("Agg")  # non-interactive backend in Colab

os.makedirs("/content/artifacts", exist_ok=True)
os.makedirs("/content/data", exist_ok=True)

#@title â¬†ï¸ Upload your local KOI CSV (use file picker)
from google.colab import files
uploaded = files.upload()  # pick your koi_cumulative.csv
LOCAL_KOI_CSV = "/content/" + next(iter(uploaded.keys()))
print("Using local CSV:", LOCAL_KOI_CSV)

#@title ðŸ“¦ KOI Classifier (train/eval/predict) â€” LOCAL CSV ONLY
import os, io, joblib, numpy as np, pandas as pd, matplotlib.pyplot as plt
from dataclasses import dataclass
from typing import List, Tuple
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,
                             roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay)
from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import HistGradientBoostingClassifier

# Expected columns (same as your script)
NUMERIC_FEATURES = [
    "koi_period","koi_time0bk","koi_duration","koi_depth","koi_model_snr","koi_impact",
    "koi_prad","koi_insol","koi_kepmag","koi_srad",
    "koi_steff","koi_slogg","koi_fpflag_nt",
    "koi_fpflag_ss","koi_fpflag_co","koi_fpflag_ec","koi_score",
]
LABEL_COLUMNS = ["koi_disposition","kepid","kepoi_name"]
SELECT_COLUMNS = LABEL_COLUMNS + NUMERIC_FEATURES

@dataclass
class TrainConfig:
    confirmed_only: bool = False
    test_size: float = 0.2
    random_state: int = 42
    n_splits_cv: int = 5
    limit_rows: int | None = 1000    # cap rows for speed
    local_csv: str = "/content/koi_cumulative.csv"  # will be overwritten by LOCAL_KOI_CSV

def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    # Make a lowercase map for case-insensitive selection
    lower_map = {c.lower(): c for c in df.columns}
    need = [c.lower() for c in SELECT_COLUMNS]
    missing = [c for c in need if c not in lower_map]
    if missing:
        raise ValueError("Your CSV is missing columns: " + ", ".join(missing))
    # Reorder and select with original casing
    ordered_cols = [lower_map[c] for c in need]
    return df[ordered_cols].rename(columns={lower_map[c]: c for c in need})

def fetch_koi_local(columns: List[str], local_path: str, limit_rows: int | None = None) -> pd.DataFrame:
    if not os.path.exists(local_path):
        raise FileNotFoundError(f"KOI CSV not found at: {local_path}")
    df = pd.read_csv(local_path, skiprows = 53)
    df = _normalize_columns(df)  # ensure required columns present, order & lower names
    if limit_rows and limit_rows > 0:
        df = df.head(int(limit_rows))
    return df

def build_dataset(cfg: TrainConfig) -> Tuple[pd.DataFrame, pd.Series]:
    df = fetch_koi_local(SELECT_COLUMNS, cfg.local_csv, cfg.limit_rows)
    df = df.dropna(subset=["koi_disposition"])
    disp = df["koi_disposition"].str.upper().str.strip()
    y = (disp == "CONFIRMED").astype(int) if cfg.confirmed_only else disp.isin(["CONFIRMED","CANDIDATE"]).astype(int)
    X = df[NUMERIC_FEATURES].apply(pd.to_numeric, errors="coerce")
    return X, y

def make_pipeline() -> Pipeline:
    pre = ColumnTransformer([("num",
                              Pipeline([("imp", SimpleImputer(strategy="median")),
                                        ("sc", StandardScaler())]),
                              NUMERIC_FEATURES)])
    clf = HistGradientBoostingClassifier(max_iter=1000, learning_rate=0.06, random_state=42)
    return Pipeline([("preprocess", pre), ("clf", clf)])

def train_and_eval(cfg: TrainConfig, outdir="/content/artifacts"):
    os.makedirs(outdir, exist_ok=True)
    print("Loading KOI data from local CSV...")
    X, y = build_dataset(cfg)
    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg.test_size, stratify=y, random_state=cfg.random_state)

    model = make_pipeline()
    cv = StratifiedKFold(n_splits=cfg.n_splits_cv, shuffle=True, random_state=cfg.random_state)
    cv_scores = cross_val_score(model, Xtr, ytr, scoring="roc_auc", cv=cv)
    print(f"CV ROC AUC: {cv_scores.mean():.3f} Â± {cv_scores.std():.3f}")

    model.fit(Xtr, ytr)
    y_prob = model.predict_proba(Xte)[:,1]
    y_pred = (y_prob>=0.5).astype(int)
    print(f"Test ROC AUC: {roc_auc_score(yte, y_prob):.3f}")
    print(f"Test Accuracy: {accuracy_score(yte, y_pred):.3f}")
    print("\nClassification report:\n", classification_report(yte, y_pred, target_names=["non-planet","planet"]))
    print("Confusion matrix:\n", confusion_matrix(yte, y_pred))

    joblib.dump({"model": model, "features": NUMERIC_FEATURES, "config": cfg.__dict__,
                 "cv_auc_mean": float(cv_scores.mean())}, os.path.join(outdir,"koi_planet_classifier.joblib"))

    RocCurveDisplay.from_predictions(yte, y_prob)
    plt.title("KOI Classifier â€” ROC"); plt.tight_layout()
    plt.savefig(os.path.join(outdir,"roc_curve.png"), dpi=160); plt.close()

    PrecisionRecallDisplay.from_predictions(yte, y_prob)
    plt.title("KOI Classifier â€” PR"); plt.tight_layout()
    plt.savefig(os.path.join(outdir,"pr_curve.png"), dpi=160); plt.close()

def evaluate(outdir="/content/artifacts"):
    b = joblib.load(os.path.join(outdir,"koi_planet_classifier.joblib"))
    model = b["model"]; cfg = TrainConfig(**b["config"])
    X, y = build_dataset(cfg)
    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=cfg.test_size, stratify=y, random_state=cfg.random_state)
    y_prob = model.predict_proba(Xte)[:,1]; y_pred = (y_prob>=0.5).astype(int)
    print(f"Test ROC AUC: {roc_auc_score(yte, y_prob):.3f}")
    print(f"Test Accuracy: {accuracy_score(yte, y_pred):.3f}")
    print("\nClassification report:\n", classification_report(yte, y_pred, target_names=["non-planet","planet"]))

def predict(csv_path:str, threshold:float=0.5, out_path="/content/predictions.csv", outdir="/content/artifacts"):
    b = joblib.load(os.path.join(outdir,"koi_planet_classifier.joblib"))
    model = b["model"]; feat = b["features"]
    df = pd.read_csv(csv_path)
    # same case-insensitive selection for safety
    lower_map = {c.lower(): c for c in df.columns}
    missing = [c for c in feat if c not in lower_map and c not in df.columns]
    if missing: raise ValueError("Missing columns: " + ", ".join(missing))
    use_cols = [c if c in df.columns else lower_map[c] for c in feat]
    X = df[use_cols].rename(columns=dict(zip(use_cols, feat)))
    y_prob = model.predict_proba(X)[:,1]
    y_pred = (y_prob>=threshold).astype(int)
    out = df.copy(); out["planet_probability"]=y_prob; out["prediction"]=np.where(y_pred==1,"planet","non-planet")
    out.to_csv(out_path, index=False); print("Wrote", out_path)

#@title ðŸ§ª Train (local CSV)
cfg = TrainConfig(
    confirmed_only=False,
    test_size=0.2,
    limit_rows=1000,           # adjust if you want more/fewer rows
    local_csv=LOCAL_KOI_CSV,   # <- from the upload/Drive cell
)
train_and_eval(cfg, outdir="/content/artifacts")

#@title ðŸ“ˆ Evaluate saved model
evaluate("/content/artifacts")

#@title ðŸ”® Predict on your own CSV with feature columns
# Example demo: take 5 rows from your KOI CSV (features only) and predict
df = pd.read_csv(LOCAL_KOI_CSV, skiprows=53)
demo = df[[c for c in df.columns if c.lower() in [f.lower() for f in NUMERIC_FEATURES]]].head(5)
demo.to_csv("/content/new_candidates.csv", index=False)

predict("/content/new_candidates.csv", threshold=0.5,
        out_path="/content/predictions.csv", outdir="/content/artifacts")

!ls -lh /content/artifacts