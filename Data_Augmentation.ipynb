{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jA2gmJCpZp9"
      },
      "outputs": [],
      "source": [
        "!pip -q install lightkurve==2.* numpy pandas scipy astropy tqdm pyarrow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional, Dict, Any, List, Tuple\n",
        "from tqdm import tqdm\n",
        "from scipy.signal import savgol_filter\n",
        "import lightkurve as lk\n",
        "\n",
        "def _to_clean_arrays(time_in, flux_in):\n",
        "    t = np.array(time_in, dtype=float)\n",
        "    f = np.array(flux_in, dtype=float)\n",
        "    m = np.isfinite(t) & np.isfinite(f)\n",
        "    t, f = t[m], f[m]\n",
        "    if len(t) == 0:\n",
        "        return t, f\n",
        "    order = np.argsort(t)\n",
        "    return t[order], f[order]\n",
        "\n",
        "def _median_cadence_min(time):\n",
        "    if len(time) < 2: return 30.0\n",
        "    dt_days = np.nanmedian(np.diff(time))\n",
        "    return float(dt_days * 24.0 * 60.0)\n",
        "\n",
        "def _savgol_detrend(time, flux, window_length=401, polyorder=2):\n",
        "    if len(flux) < 7:\n",
        "        return time, flux\n",
        "    wl = max(5, int(window_length))\n",
        "    wl = wl if wl % 2 == 1 else wl + 1\n",
        "    wl = min(wl, len(flux) - (1 - len(flux) % 2))\n",
        "    if wl < 5:\n",
        "        return time, flux\n",
        "    trend = savgol_filter(flux, window_length=wl, polyorder=polyorder, mode=\"interp\")\n",
        "    med = np.nanmedian(trend) if np.isfinite(trend).any() else 1.0\n",
        "    trend = np.where(trend == 0, med, trend)\n",
        "    return time, flux / trend - 1.0\n",
        "\n",
        "def _lk_flatten(time, flux, window_length=401, polyorder=2, break_tolerance=5):\n",
        "    try:\n",
        "        lc = lk.LightCurve(time=time, flux=flux)\n",
        "        wl = max(5, int(window_length))\n",
        "        wl = wl if wl % 2 == 1 else wl + 1\n",
        "        lc_flat = lc.flatten(window_length=wl, polyorder=polyorder, break_tolerance=break_tolerance)\n",
        "        return np.array(lc_flat.time.value), np.array(lc_flat.flux.value)\n",
        "    except Exception:\n",
        "        return _savgol_detrend(time, flux, window_length=window_length, polyorder=polyorder)\n",
        "\n",
        "def detrend_if_needed(time, flux, already_detrended: bool, cadence_min: Optional[float]=None,\n",
        "                      method=\"lightkurve\", max_transit_hours=10.0):\n",
        "    t, f = _to_clean_arrays(time, flux)\n",
        "    if already_detrended:\n",
        "        return t, f - np.nanmedian(f)\n",
        "    if cadence_min is None: cadence_min = _median_cadence_min(t)\n",
        "    target_minutes = max_transit_hours * 60.0 * 2.5\n",
        "    wl = max(51, int(round(target_minutes / max(cadence_min, 1e-6))))\n",
        "    wl = wl if wl % 2 == 1 else wl + 1\n",
        "    if method == \"lightkurve\":\n",
        "        t, fd = _lk_flatten(t, f, window_length=wl, polyorder=2)\n",
        "    else:\n",
        "        t, fd = _savgol_detrend(t, f, window_length=wl, polyorder=2)\n",
        "    return t, fd - np.nanmedian(fd)\n",
        "\n",
        "def sample_transit_params(\n",
        "    period_range=(0.5, 30.0), duration_hours_range=(1.0, 10.0), depth_ppm_range=(200, 5000),\n",
        "    t0: Optional[float]=None, rng: Optional[np.random.Generator]=None\n",
        ") -> Dict[str, float]:\n",
        "    rng = rng or np.random.default_rng()\n",
        "    P = 10**rng.uniform(np.log10(period_range[0]), np.log10(period_range[1]))\n",
        "    dur_h = 10**rng.uniform(np.log10(duration_hours_range[0]), np.log10(duration_hours_range[1]))\n",
        "    depth_ppm = 10**rng.uniform(np.log10(depth_ppm_range[0]), np.log10(depth_ppm_range[1]))\n",
        "    return {\"period\": P, \"duration_days\": dur_h/24.0, \"depth\": depth_ppm*1e-6, \"t0\": t0}\n",
        "\n",
        "def box_transit_model(time, period, duration_days, depth, t0=None):\n",
        "    t = np.asarray(time)\n",
        "    if t0 is None:\n",
        "        t0 = t.min() + 0.25*period\n",
        "    phase = ((t - t0) % period) / period\n",
        "    half = 0.5 * duration_days / period  # fraction of phase\n",
        "    in_transit = (phase < half) | (phase > 1 - half)\n",
        "    model = np.zeros_like(t, dtype=float)\n",
        "    model[in_transit] = -depth\n",
        "    return model\n",
        "\n",
        "def inject_transit(flux_detrended, model):\n",
        "    return flux_detrended + model\n",
        "\n",
        "def add_white_noise(flux, sigma_ppm=300, rng=None):\n",
        "    rng = rng or np.random.default_rng()\n",
        "    sigma = sigma_ppm * 1e-6\n",
        "    return flux + rng.normal(0.0, sigma, size=len(flux))\n",
        "\n",
        "def add_red_noise_ar1(flux, rho=0.5, sigma_ppm=300, rng=None):\n",
        "    rng = rng or np.random.default_rng()\n",
        "    sigma = sigma_ppm * 1e-6\n",
        "    eps_sd = sigma * np.sqrt(1 - rho**2)\n",
        "    red = np.zeros_like(flux, dtype=float)\n",
        "    for i in range(1, len(flux)):\n",
        "        red[i] = rho * red[i-1] + rng.normal(0.0, eps_sd)\n",
        "    return flux + red\n",
        "\n",
        "def insert_cadence_gaps(time, flux, gap_prob=0.01, block_drop_prob=0.02, block_len=50, rng=None):\n",
        "    rng = rng or np.random.default_rng()\n",
        "    keep = np.ones(len(time), dtype=bool)\n",
        "    single = rng.uniform(size=len(time)) > gap_prob\n",
        "    keep &= single\n",
        "    if rng.uniform() < block_drop_prob and len(time) > block_len:\n",
        "        start = rng.integers(0, len(time)-block_len)\n",
        "        keep[start:start+block_len] = False\n",
        "    return time[keep], flux[keep]\n",
        "\n",
        "def inject_flare(flux, n_flares=1, amp_ppm_range=(200, 5000), tau_hours_range=(0.2, 3.0), cadence_min=30.0, rng=None):\n",
        "    rng = rng or np.random.default_rng()\n",
        "    f = flux.copy()\n",
        "    n = len(f)\n",
        "    for _ in range(n_flares):\n",
        "        idx0 = rng.integers(low=0, high=max(1, n-3))\n",
        "        amp = 10**rng.uniform(np.log10(amp_ppm_range[0]), np.log10(amp_ppm_range[1])) * 1e-6\n",
        "        tau_h = 10**rng.uniform(np.log10(tau_hours_range[0]), np.log10(tau_hours_range[1]))\n",
        "        tau_cad = max(1.0, tau_h * 60.0 / max(cadence_min, 1e-6))\n",
        "        k = np.arange(0, min(int(8*tau_cad), n-idx0))\n",
        "        f[idx0:idx0+len(k)] += amp * np.exp(-k / tau_cad)\n",
        "    return f\n"
      ],
      "metadata": {
        "id": "bIiWwXMxpkbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_block(row: pd.Series,\n",
        "                  already_detrended: bool,\n",
        "                  n_pos: int = 2,\n",
        "                  n_neg: int = 2,\n",
        "                  rng: Optional[np.random.Generator] = None,\n",
        "                  # transit sampling\n",
        "                  period_range=(0.5, 30.0),\n",
        "                  duration_hours_range=(1.0, 10.0),\n",
        "                  depth_ppm_range=(200, 5000),\n",
        "                  # noise knobs\n",
        "                  white_sigma_ppm=300,\n",
        "                  red_rho=0.5,\n",
        "                  red_sigma_ppm=200,\n",
        "                  flare_prob=0.2,\n",
        "                  max_flares=2,\n",
        "                  gap_prob=0.01,\n",
        "                  block_drop_prob=0.02,\n",
        "                  block_len=50,\n",
        "                  detrend_method=\"lightkurve\",\n",
        "                  max_transit_hours=10.0) -> List[Dict[str, Any]]:\n",
        "\n",
        "    rng = rng or np.random.default_rng()\n",
        "    time = row.get(\"time\"); flux = row.get(\"flux\")\n",
        "    if time is None or flux is None:\n",
        "        return []\n",
        "    cadence_min = row.get(\"cadence_min\") or _median_cadence_min(np.array(time))\n",
        "    t, f0 = detrend_if_needed(time, flux, already_detrended, cadence_min, method=detrend_method, max_transit_hours=max_transit_hours)\n",
        "\n",
        "    out = []\n",
        "\n",
        "    for _ in range(max(0, int(n_pos))):\n",
        "        pars = sample_transit_params(period_range, duration_hours_range, depth_ppm_range, rng=rng)\n",
        "        model = box_transit_model(t, pars[\"period\"], pars[\"duration_days\"], pars[\"depth\"], pars[\"t0\"])\n",
        "        f = inject_transit(f0, model)\n",
        "        f = add_white_noise(f, sigma_ppm=white_sigma_ppm, rng=rng)\n",
        "        f = add_red_noise_ar1(f, rho=red_rho, sigma_ppm=red_sigma_ppm, rng=rng)\n",
        "        if rng.uniform() < flare_prob:\n",
        "            f = inject_flare(f, n_flares=rng.integers(1, max_flares+1), cadence_min=cadence_min, rng=rng)\n",
        "\n",
        "        t_aug, f_aug = insert_cadence_gaps(t, f, gap_prob=gap_prob, block_drop_prob=block_drop_prob, block_len=block_len, rng=rng)\n",
        "\n",
        "        out.append({\n",
        "            \"obs_block_id\": row.get(\"obs_block_id\"),\n",
        "            \"target_id\": row.get(\"target_id\"),\n",
        "            \"mission\": row.get(\"mission\"),\n",
        "            \"sector\": row.get(\"sector\"),\n",
        "            \"quarter\": row.get(\"quarter\"),\n",
        "            \"campaign\": row.get(\"campaign\"),\n",
        "            \"label_aug\": 1,\n",
        "            \"aug_type\": \"transit+noise\",\n",
        "            \"time\": t_aug.tolist(),\n",
        "            \"flux\": f_aug.tolist(),\n",
        "            \"cadence_min\": float(cadence_min),\n",
        "            # provenance\n",
        "            \"period\": float(pars[\"period\"]),\n",
        "            \"duration_days\": float(pars[\"duration_days\"]),\n",
        "            \"depth\": float(pars[\"depth\"]),\n",
        "            \"white_sigma_ppm\": float(white_sigma_ppm),\n",
        "            \"red_rho\": float(red_rho),\n",
        "            \"red_sigma_ppm\": float(red_sigma_ppm),\n",
        "            \"flare_used\": float(1.0 if \"n_flares\" else 0.0),\n",
        "            \"gap_prob\": float(gap_prob),\n",
        "            \"block_drop_prob\": float(block_drop_prob),\n",
        "        })\n",
        "\n",
        "    for _ in range(max(0, int(n_neg))):\n",
        "        f = f0.copy()\n",
        "        f = add_white_noise(f, sigma_ppm=white_sigma_ppm, rng=rng)\n",
        "        f = add_red_noise_ar1(f, rho=red_rho, sigma_ppm=red_sigma_ppm, rng=rng)\n",
        "        if rng.uniform() < flare_prob:\n",
        "            f = inject_flare(f, n_flares=rng.integers(1, max_flares+1), cadence_min=cadence_min, rng=rng)\n",
        "        t_aug, f_aug = insert_cadence_gaps(t, f, gap_prob=gap_prob, block_drop_prob=block_drop_prob, block_len=block_len, rng=rng)\n",
        "\n",
        "        out.append({\n",
        "            \"obs_block_id\": row.get(\"obs_block_id\"),\n",
        "            \"target_id\": row.get(\"target_id\"),\n",
        "            \"mission\": row.get(\"mission\"),\n",
        "            \"sector\": row.get(\"sector\"),\n",
        "            \"quarter\": row.get(\"quarter\"),\n",
        "            \"campaign\": row.get(\"campaign\"),\n",
        "            \"label_aug\": 0,\n",
        "            \"aug_type\": \"noise-only\",\n",
        "            \"time\": t_aug.tolist(),\n",
        "            \"flux\": f_aug.tolist(),\n",
        "            \"cadence_min\": float(cadence_min),\n",
        "            \"white_sigma_ppm\": float(white_sigma_ppm),\n",
        "            \"red_rho\": float(red_rho),\n",
        "            \"red_sigma_ppm\": float(red_sigma_ppm),\n",
        "            \"flare_used\": float(1.0 if \"n_flares\" else 0.0),\n",
        "            \"gap_prob\": float(gap_prob),\n",
        "            \"block_drop_prob\": float(block_drop_prob),\n",
        "        })\n",
        "\n",
        "    return out\n",
        "\n",
        "def build_augmented_dataset(\n",
        "    vet_df: pd.DataFrame,\n",
        "    already_detrended: bool = False,\n",
        "    n_pos_per_block: int = 2,\n",
        "    n_neg_per_block: int = 2,\n",
        "    rng_seed: int = 42,\n",
        "    **kwargs\n",
        ") -> pd.DataFrame:\n",
        "    rng = np.random.default_rng(rng_seed)\n",
        "    recs: List[Dict[str, Any]] = []\n",
        "    for _, row in tqdm(vet_df.iterrows(), total=len(vet_df), desc=\"Augmenting\"):\n",
        "        try:\n",
        "            recs.extend(augment_block(row, already_detrended, n_pos_per_block, n_neg_per_block, rng=rng, **kwargs))\n",
        "        except Exception as e:\n",
        "            print(f\"[WARN] augment failed for {row.get('obs_block_id','?')}: {repr(e)}\")\n",
        "    return pd.DataFrame.from_records(recs)\n"
      ],
      "metadata": {
        "id": "YUv5BuzsqHlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "VET_PARQUET = \"/content//vetting_kepler.parquet\"  # update path\n",
        "AUG_OUT_PARQUET = \"/content/drive/augmented_training.parquet\"\n",
        "\n",
        "vet_df = pd.read_parquet(VET_PARQUET)\n",
        "print(\"Loaded blocks:\", len(vet_df))\n",
        "display(vet_df.head(2))\n",
        "aug_df = build_augmented_dataset(\n",
        "    vet_df,\n",
        "    already_detrended=False,\n",
        "    n_pos_per_block=2,\n",
        "    n_neg_per_block=2,\n",
        "    rng_seed=123,\n",
        "    period_range=(0.5, 30.0),\n",
        "    duration_hours_range=(1.0, 10.0),\n",
        "    depth_ppm_range=(200, 5000),\n",
        "    white_sigma_ppm=300,\n",
        "    red_rho=0.5,\n",
        "    red_sigma_ppm=200,\n",
        "    flare_prob=0.2,\n",
        "    max_flares=2,\n",
        "    gap_prob=0.01,\n",
        "    block_drop_prob=0.02,\n",
        "    block_len=50,\n",
        "    detrend_method=\"lightkurve\",\n",
        "    max_transit_hours=10.0,\n",
        ")\n",
        "\n",
        "print(\"Augmented samples:\", len(aug_df))\n",
        "display(aug_df.head(3))\n",
        "aug_df.to_parquet(AUG_OUT_PARQUET, index=False)\n",
        "print(\"Saved augmented set â†’\", AUG_OUT_PARQUET)"
      ],
      "metadata": {
        "id": "sQuaerpWqTwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def quick_plot_sample(sample_row):\n",
        "    t = np.array(sample_row[\"time\"])\n",
        "    f = np.array(sample_row[\"flux\"])\n",
        "    plt.figure(figsize=(10,3))\n",
        "    plt.plot(t, f, lw=0.5)\n",
        "    plt.xlabel(\"Time (BKJD/BTJD)\")\n",
        "    plt.ylabel(\"Flux (detrended)\")\n",
        "    title = f\"{sample_row.get('aug_type','?')}  label={sample_row.get('label_aug','?')}\"\n",
        "    if \"period\" in sample_row and not np.isnan(sample_row.get(\"period\", np.nan)):\n",
        "        title += f\"  P={sample_row['period']:.2f} d\"\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "if not aug_df.empty:\n",
        "    quick_plot_sample(aug_df.iloc[0])"
      ],
      "metadata": {
        "id": "mb3sXupfqh2q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}